apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: cilium
  namespace: kube-system
  # annotations:
  #   meta.helm.sh/release-name: cilium
  #   meta.helm.sh/release-namespace: kube-system
  # labels:
  #   app.kubernetes.io/managed-by: Helm
spec:
  interval: 30m
  chart:
    spec:
      chart: cilium
      version: 1.16.3
      sourceRef:
        kind: HelmRepository
        name: cilium-charts
        namespace: flux-system
      interval: 5m
  install:
    remediation:
      retries: 3
  upgrade:
    timeout: 15m
    cleanupOnFail: true
    remediation:
      strategy: rollback
      retries: 3
  values:
    securityContext:
      capabilities:
        ciliumAgent:
        - CHOWN
        - KILL
        - NET_ADMIN
        - NET_RAW
        - IPC_LOCK
        - SYS_ADMIN
        - SYS_RESOURCE
        - DAC_OVERRIDE
        - FOWNER
        - SETGID
        - SETUID
        cleanCiliumState:
        - NET_ADMIN
        - SYS_ADMIN
        - SYS_RESOURCE
    cgroup:
      autoMount:
        enabled: false
      hostRoot: /sys/fs/cgroup

    cluster:
      name: "${CLUSTER_NAME}"
      id: "${CLUSTER_ID}"

    cni:
      exclusive: false # Needed to allow Cillium to work properly with Multus

    rollOutCiliumPods: true
    localRedirectPolicy: true

    # Changed from "strict" to "true"
    kubeProxyReplacement: "true"
    kubeProxyReplacementHealthzBindAddr: 0.0.0.0:10256

    ipv4NativeRoutingCIDR: ${NETWORK_K8S_POD_CIDR}

    # k8sServiceHost: "cluster-2.${HARDWARE_DOMAIN}"
    # k8sServicePort: 6443
    # Changed to use KubePrism instead of the HAProxy instance. 
    # Should allow for cluster comms even when HAProxy goes down
    k8sServiceHost: localhost
    k8sServicePort: 7445

    loadBalancer:
      algorithm: "maglev"
      mode: "dsr"

    ipam:
      mode: "kubernetes"

    ingressController:
      enabled: true
      loadbalancerMode: shared

    service:
      loadBalancerIP: "${LB_INGRESS}"

    # tunnel: "disabled"
    tunnelProtocol: "" #Disables tunnel
    routingMode: "native"

    autoDirectNodeRoutes: true

    bandwidthManager:
      enabled: true
      bbr: true

    bpf:
      masquerade: false
      tproxy: true

    # endpointRoutes:
    #   enabled: true

    operator:
      rollOutPods: true

    hubble:
      enabled: true
      serviceMonitor:
        enabled: true
      dashboards:
        enabled: true
        label: grafana_dashboard
        namespace: system-monitoring
        labelValue: "1"
        annotations: {}
      metrics:
        enabled:
        - dns:query;ignoreAAAA
        - drop
        - tcp
        - flow
        - port-distribution
        - icmp
        - http
      relay:
        enabled: true
        rollOutPods: true
      ui:
        enabled: true
        rollOutPods: true
        ingress:
          enabled: true
          className: "internal-nginx"
          hosts:
          - &host "hubble.${INGRESS_DOMAIN}"
          tls:
          - hosts:
            - *host

    bgpControlPlane:
      enabled: true
    bgp:
      enabled: false
      announce:
        loadbalancerIP: true
        podCIDR: true
